{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/ph/LLM2/swift')\n",
    "sys.path.insert(0,'/home/ph/LLM2/swift')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试qwen-vl-chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ph/anaconda3/envs/torch2.1/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-05-06 13:05:32,572 - modelscope - INFO - PyTorch version 2.2.1 Found.\n",
      "2024-05-06 13:05:32,574 - modelscope - INFO - Loading ast index from /home/ph/.cache/modelscope/ast_indexer\n",
      "2024-05-06 13:05:32,611 - modelscope - INFO - Loading done! Current index file version is 1.10.0, with md5 f6e226a8578971e8fd7923bb0e86893b and a total number of 946 components indexed\n",
      "[INFO:swift] Successfully registered `/home/ph/LLM2/swift/swift/llm/data/dataset_info.json`\n",
      "2024-05-06 13:05:33,254\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "[INFO:swift] Loading the model using model_dir: /home/ph/LLM2/VL/Qwen-VL-Chat\n",
      "[INFO:swift] Setting torch_dtype: torch.bfloat16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "template_type: qwen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 10/10 [00:05<00:00,  1.89it/s]\n",
      "[INFO:swift] model.max_model_len: 2048\n",
      "[INFO:swift] Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query: Picture 1: <img>https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen-VL/assets/demo.jpeg</img>\n",
      "这是什么\n",
      "response: 图中是一名女子在沙滩上和狗玩耍，旁边的狗是一只拉布拉多犬，它们处于沙滩上。\n",
      "query: 输出击掌的检测框\n",
      "response: <ref>击掌</ref><box>(523,513),(584,605)</box>\n",
      "history: [['Picture 1: <img>https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen-VL/assets/demo.jpeg</img>\\n这是什么', '图中是一名女子在沙滩上和狗玩耍，旁边的狗是一只拉布拉多犬，它们处于沙滩上。'], ['输出击掌的检测框', '<ref>击掌</ref><box>(523,513),(584,605)</box>']]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '4'\n",
    "\n",
    "from swift.llm import (\n",
    "    get_model_tokenizer, get_template, inference, ModelType, get_default_template_type,\n",
    ")\n",
    "from swift.utils import seed_everything\n",
    "\n",
    "model_type = ModelType.qwen_vl_chat\n",
    "template_type = get_default_template_type(model_type)\n",
    "print(f'template_type: {template_type}')  # template_type: qwen\n",
    "\n",
    "model, tokenizer = get_model_tokenizer(model_type, model_kwargs={'device_map': 'auto'})\n",
    "\n",
    "template = get_template(template_type, tokenizer)\n",
    "seed_everything(42)\n",
    "query = tokenizer.from_list_format([\n",
    "    {'image': 'https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen-VL/assets/demo.jpeg'},\n",
    "    {'text': '这是什么'},\n",
    "])\n",
    "response, history = inference(model, template, query)\n",
    "print(f'query: {query}')\n",
    "print(f'response: {response}')\n",
    "query = '输出击掌的检测框'\n",
    "response, history = inference(model, template, query, history)\n",
    "print(f'query: {query}')\n",
    "print(f'response: {response}')\n",
    "print(f'history: {history}')\n",
    "image = tokenizer.draw_bbox_on_latest_picture(response, history)\n",
    "image.save('output_chat.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试sft更改认知"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '6'\n",
    "import sys\n",
    "sys.path.append('/home/ph/LLM2/swift')\n",
    "sys.path.insert(0,'/home/ph/LLM2/swift')\n",
    "from swift.llm import DatasetName, ModelType, SftArguments, sft_main\n",
    "\n",
    "sft_args = SftArguments(\n",
    "    model_type=ModelType.qwen_14b_chat,\n",
    "    # model_id_or_path='/home/ph/LLM/Qwen1.5/Qwen1.5-14B-Chat-GPTQ-Int4',  model_cache_dir='/home/ph/LLM/Qwen1.5/Qwen1.5-14B-Chat-GPTQ-Int4',\n",
    "    dataset=[DatasetName.sharegpt_gpt4_mini],\n",
    "    train_dataset_sample=1000,\n",
    "    logging_steps=5,\n",
    "    max_length=2048,\n",
    "    warmup_ratio=0.4,\n",
    "    output_dir='output',\n",
    "    lora_target_modules=['ALL'],   # 在所有的linear层(包括qkvo以及mlp)加lora. 这通常是效果最好的.\n",
    "    self_cognition_sample=500,\n",
    "    model_name=['猴乐乐', 'houlele'],\n",
    "    model_author=['同元智算', 'Tongyuan intelligence calculation'])\n",
    "output = sft_main(sft_args)\n",
    "best_model_checkpoint = output['best_model_checkpoint']\n",
    "print(f'best_model_checkpoint: {best_model_checkpoint}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## datasets加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-06 16:43:16,469 - modelscope - INFO - PyTorch version 2.2.1 Found.\n",
      "2024-05-06 16:43:16,471 - modelscope - INFO - Loading ast index from /home/ph/.cache/modelscope/ast_indexer\n",
      "2024-05-06 16:43:16,518 - modelscope - INFO - Loading done! Current index file version is 1.13.3, with md5 b97acdcdf6b803b3e9e523c04105cb52 and a total number of 972 components indexed\n",
      "/home/ph/anaconda3/envs/torch2.1/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-05-06 16:43:18,497 - modelscope - WARNING - Authentication has expired, please re-login if you need to access private models or datasets.\n",
      "2024-05-06 16:43:18,881 - modelscope - INFO - dataset_type: 4\n",
      "2024-05-06 16:43:18,885 - modelscope - WARNING - Authentication has expired, please re-login if you need to access private models or datasets.\n",
      "2024-05-06 16:43:19,299 - modelscope - WARNING - Authentication has expired, please re-login if you need to access private models or datasets.\n",
      "2024-05-06 16:43:20,332 - modelscope - WARNING - Authentication has expired, please re-login if you need to access private models or datasets.\n",
      "2024-05-06 16:43:20,622 - modelscope - INFO - Downloading to /home/ph/.cache/modelscope/hub/datasets/96fc4d514f93efc9a2555c6caf3a15206e6d427833c15f579ab587ec54837819.incomplete\n",
      "Downloading readme: 100%|██████████| 1.23k/1.23k [00:00<00:00, 2.79MB/s]\n",
      "2024-05-06 16:43:20,885 - modelscope - INFO - storing https://www.modelscope.cn/api/v1/datasets/AI-ModelScope/alpaca-gpt4-data-zh/repo?Source=SDK&Revision=master&FilePath=README.md in cache at /home/ph/.cache/modelscope/hub/datasets/96fc4d514f93efc9a2555c6caf3a15206e6d427833c15f579ab587ec54837819\n",
      "2024-05-06 16:43:20,887 - modelscope - INFO - creating metadata file for /home/ph/.cache/modelscope/hub/datasets/96fc4d514f93efc9a2555c6caf3a15206e6d427833c15f579ab587ec54837819\n",
      "2024-05-06 16:43:20,893 - modelscope - WARNING - Authentication has expired, please re-login if you need to access private models or datasets.\n",
      "2024-05-06 16:43:21,223 - modelscope - WARNING - Authentication has expired, please re-login if you need to access private models or datasets.\n",
      "2024-05-06 16:43:21,497 - modelscope - WARNING - Authentication has expired, please re-login if you need to access private models or datasets.\n",
      "2024-05-06 16:43:21,867 - modelscope - WARNING - Authentication has expired, please re-login if you need to access private models or datasets.\n",
      "2024-05-06 16:43:22,153 - modelscope - WARNING - Authentication has expired, please re-login if you need to access private models or datasets.\n",
      "2024-05-06 16:43:22,508 - modelscope - WARNING - Authentication has expired, please re-login if you need to access private models or datasets.\n",
      "2024-05-06 16:43:22,777 - modelscope - WARNING - Authentication has expired, please re-login if you need to access private models or datasets.\n",
      "2024-05-06 16:43:23,144 - modelscope - WARNING - Authentication has expired, please re-login if you need to access private models or datasets.\n",
      "2024-05-06 16:43:23,432 - modelscope - WARNING - Authentication has expired, please re-login if you need to access private models or datasets.\n",
      "2024-05-06 16:43:23,779 - modelscope - WARNING - Authentication has expired, please re-login if you need to access private models or datasets.\n",
      "2024-05-06 16:43:24,090 - modelscope - WARNING - Authentication has expired, please re-login if you need to access private models or datasets.\n",
      "2024-05-06 16:43:24,466 - modelscope - WARNING - Authentication has expired, please re-login if you need to access private models or datasets.\n",
      "2024-05-06 16:43:24,847 - modelscope - WARNING - Authentication has expired, please re-login if you need to access private models or datasets.\n",
      "2024-05-06 16:43:25,478 - modelscope - INFO - Downloading to /home/ph/LLM2/swift/datasets/downloads/ee3959cc16ee530c43270b123e2d8694a153a70d1b9a10d1e697df701b3fd791.incomplete\n",
      "Downloading data: 31.8MB [00:06, 5.03MB/s]\n",
      "2024-05-06 16:43:32,571 - modelscope - INFO - storing https://www.modelscope.cn/api/v1/datasets/AI-ModelScope/alpaca-gpt4-data-zh/repo?Source=SDK&Revision=master&FilePath=train.csv in cache at /home/ph/LLM2/swift/datasets/downloads/ee3959cc16ee530c43270b123e2d8694a153a70d1b9a10d1e697df701b3fd791\n",
      "2024-05-06 16:43:32,573 - modelscope - INFO - creating metadata file for /home/ph/LLM2/swift/datasets/downloads/ee3959cc16ee530c43270b123e2d8694a153a70d1b9a10d1e697df701b3fd791\n",
      "Generating train split: 48818 examples [00:00, 69177.86 examples/s]\n",
      "2024-05-06 16:43:33,295 - modelscope - WARNING - Authentication has expired, please re-login if you need to access private models or datasets.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': '保持健康的三个提示。', 'input': None, 'output': '以下是保持健康的三个提示：\\n\\n1. 保持身体活动。每天做适当的身体运动，如散步、跑步或游泳，能促进心血管健康，增强肌肉力量，并有助于减少体重。\\n\\n2. 均衡饮食。每天食用新鲜的蔬菜、水果、全谷物和脂肪含量低的蛋白质食物，避免高糖、高脂肪和加工食品，以保持健康的饮食习惯。\\n\\n3. 睡眠充足。睡眠对人体健康至关重要，成年人每天应保证 7-8 小时的睡眠。良好的睡眠有助于减轻压力，促进身体恢复，并提高注意力和记忆力。'}\n"
     ]
    }
   ],
   "source": [
    "# 自定义\n",
    "import os\n",
    "from modelscope.msdatasets import MsDataset\n",
    "custom_cache_dir='/home/ph/LLM2/swift/datasets'\n",
    "if not os.path.exists(custom_cache_dir):\n",
    "    os.makedirs(custom_cache_dir)\n",
    "ds = MsDataset.load(dataset_name='AI-ModelScope/alpaca-gpt4-data-zh',subset_name='default' ,split=\"train\",\n",
    "                    download_mode= 'reuse_dataset_if_exists',cache_dir=custom_cache_dir)\n",
    "print(next(iter(ds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-06 16:41:53,357 - modelscope - INFO - PyTorch version 2.2.1 Found.\n",
      "2024-05-06 16:41:53,360 - modelscope - INFO - Loading ast index from /home/ph/.cache/modelscope/ast_indexer\n",
      "2024-05-06 16:41:53,410 - modelscope - INFO - No valid ast index found from /home/ph/.cache/modelscope/ast_indexer, generating ast index from prebuilt!\n",
      "2024-05-06 16:41:53,480 - modelscope - INFO - Loading done! Current index file version is 1.13.3, with md5 b97acdcdf6b803b3e9e523c04105cb52 and a total number of 972 components indexed\n",
      "/home/ph/anaconda3/envs/torch2.1/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'RepoFolder' from 'huggingface_hub.hf_api' (/home/ph/anaconda3/envs/torch2.1/lib/python3.9/site-packages/huggingface_hub/hf_api.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodelscope\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmsdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MsDataset\n\u001b[1;32m      3\u001b[0m custom_cache_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/ph/LLM2/swift/datasets\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(custom_cache_dir):\n",
      "File \u001b[0;32m~/anaconda3/envs/torch2.1/lib/python3.9/site-packages/modelscope/msdatasets/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright (c) Alibaba, Inc. and its affiliates.\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mms_dataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MsDataset\n",
      "File \u001b[0;32m~/anaconda3/envs/torch2.1/lib/python3.9/site-packages/modelscope/msdatasets/ms_dataset.py:24\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodelscope\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmsdatasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset_cls\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcustom_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbuilder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \\\n\u001b[1;32m     22\u001b[0m     build_custom_dataset\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodelscope\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmsdatasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdelete_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DatasetDeleteManager\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodelscope\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmsdatasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhf_datasets_util\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \\\n\u001b[1;32m     25\u001b[0m     load_dataset \u001b[38;5;28;01mas\u001b[39;00m hf_load_dataset_wrapper\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodelscope\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmsdatasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mupload_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DatasetUploadManager\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodelscope\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m build_preprocessor\n",
      "File \u001b[0;32m~/anaconda3/envs/torch2.1/lib/python3.9/site-packages/modelscope/msdatasets/utils/hf_datasets_util.py:57\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhuggingface_hub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (DatasetCard, DatasetCardData, HfFileSystem)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhuggingface_hub\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhf_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DatasetInfo \u001b[38;5;28;01mas\u001b[39;00m HfDatasetInfo\n\u001b[0;32m---> 57\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhuggingface_hub\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhf_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HfApi, RepoFile, RepoFolder\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpackaging\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m version\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodelscope\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HubApi\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'RepoFolder' from 'huggingface_hub.hf_api' (/home/ph/anaconda3/envs/torch2.1/lib/python3.9/site-packages/huggingface_hub/hf_api.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from modelscope.msdatasets import MsDataset\n",
    "custom_cache_dir='/home/ph/LLM2/swift/datasets'\n",
    "if not os.path.exists(custom_cache_dir):\n",
    "    os.makedirs(custom_cache_dir)\n",
    "\n",
    "ds = MsDataset.load(\"alpaca-gpt4-data-zh\", namespace=\"AI-ModelScope\", split=\"train\",cache_dir=custom_cache_dir)\n",
    "print(next(iter(ds)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2.1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
