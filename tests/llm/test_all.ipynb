{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/ph/LLM2/swift')\n",
    "sys.path.insert(0,'/home/ph/LLM2/swift')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试qwen-vl-chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ph/anaconda3/envs/torch2.1/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-05-06 10:09:52,707 - modelscope - INFO - PyTorch version 2.2.1 Found.\n",
      "2024-05-06 10:09:52,709 - modelscope - INFO - Loading ast index from /home/ph/.cache/modelscope/ast_indexer\n",
      "2024-05-06 10:09:52,745 - modelscope - INFO - Loading done! Current index file version is 1.10.0, with md5 f6e226a8578971e8fd7923bb0e86893b and a total number of 946 components indexed\n",
      "2024-05-06 10:09:53,355\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "[INFO:swift] Loading the model using model_dir: /home/ph/LLM2/VL/Qwen-VL-Chat\n",
      "[INFO:swift] Setting torch_dtype: torch.bfloat16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "template_type: qwen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 10/10 [00:04<00:00,  2.20it/s]\n",
      "[INFO:swift] model.max_model_len: 2048\n",
      "[INFO:swift] Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query: Picture 1: <img>https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen-VL/assets/demo.jpeg</img>\n",
      "这是什么\n",
      "response: 图中是一名女子在沙滩上和狗玩耍，旁边的狗是一只拉布拉多犬，它们处于沙滩上。\n",
      "query: 输出击掌的检测框\n",
      "response: <ref>击掌</ref><box>(523,513),(584,605)</box>\n",
      "history: [['Picture 1: <img>https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen-VL/assets/demo.jpeg</img>\\n这是什么', '图中是一名女子在沙滩上和狗玩耍，旁边的狗是一只拉布拉多犬，它们处于沙滩上。'], ['输出击掌的检测框', '<ref>击掌</ref><box>(523,513),(584,605)</box>']]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '4'\n",
    "\n",
    "from swift.llm import (\n",
    "    get_model_tokenizer, get_template, inference, ModelType, get_default_template_type,\n",
    ")\n",
    "from swift.utils import seed_everything\n",
    "\n",
    "model_type = ModelType.qwen_vl_chat\n",
    "template_type = get_default_template_type(model_type)\n",
    "print(f'template_type: {template_type}')  # template_type: qwen\n",
    "\n",
    "model, tokenizer = get_model_tokenizer(model_type, model_kwargs={'device_map': 'auto'})\n",
    "\n",
    "template = get_template(template_type, tokenizer)\n",
    "seed_everything(42)\n",
    "query = tokenizer.from_list_format([\n",
    "    {'image': 'https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen-VL/assets/demo.jpeg'},\n",
    "    {'text': '这是什么'},\n",
    "])\n",
    "response, history = inference(model, template, query)\n",
    "print(f'query: {query}')\n",
    "print(f'response: {response}')\n",
    "query = '输出击掌的检测框'\n",
    "response, history = inference(model, template, query, history)\n",
    "print(f'query: {query}')\n",
    "print(f'response: {response}')\n",
    "print(f'history: {history}')\n",
    "image = tokenizer.draw_bbox_on_latest_picture(response, history)\n",
    "image.save('output_chat.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试sft更改认知"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ph/anaconda3/envs/torch2.1/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-05-06 10:31:31,921 - modelscope - INFO - PyTorch version 2.2.1 Found.\n",
      "2024-05-06 10:31:31,927 - modelscope - INFO - Loading ast index from /home/ph/.cache/modelscope/ast_indexer\n",
      "2024-05-06 10:31:31,967 - modelscope - INFO - Loading done! Current index file version is 1.10.0, with md5 f6e226a8578971e8fd7923bb0e86893b and a total number of 946 components indexed\n",
      "2024-05-06 10:31:32,563\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "[INFO:swift] Setting template_type: qwen\n",
      "[INFO:swift] Setting args.lazy_tokenize: False\n",
      "[INFO:swift] output_dir: /home/ph/LLM2/swift/tests/llm/output/qwen-14b-chat/v1-20240506-103132\n",
      "[INFO:swift] Start time of running main: 2024-05-06 10:31:32.663460\n",
      "[INFO:swift] args: SftArguments(model_type='qwen-14b-chat', model_id_or_path='/home/ph/LLM/Qwen-14B-main/Qwen-14B-Chat', model_revision='master', model_layer_cls_name=None, sft_type='lora', freeze_parameters=0.0, additional_trainable_parameters=[], tuner_backend='peft', template_type='qwen', output_dir='/home/ph/LLM2/swift/tests/llm/output/qwen-14b-chat/v1-20240506-103132', add_output_dir_suffix=True, ddp_backend=None, ddp_find_unused_parameters=None, ddp_broadcast_buffers=None, seed=42, resume_from_checkpoint=None, ignore_data_skip=False, dtype='bf16', dataset=['sharegpt-gpt4-mini'], dataset_seed=42, dataset_test_ratio=0.01, train_dataset_sample=1000, train_dataset_mix_ratio=0.0, train_dataset_mix_ds=['ms-bench'], val_dataset_sample=None, use_loss_scale=False, system=None, max_length=2048, truncation_strategy='delete', check_dataset_strategy='none', custom_train_dataset_path=[], custom_val_dataset_path=[], self_cognition_sample=500, model_name=['猴乐乐', 'houlele'], model_author=['同元智算', 'Tongyuan intelligence calculation'], quantization_bit=0, bnb_4bit_comp_dtype='bf16', bnb_4bit_quant_type='nf4', bnb_4bit_use_double_quant=True, bnb_4bit_quant_storage=None, lora_target_modules=[], lora_rank=8, lora_alpha=32, lora_dropout_p=0.05, lora_bias_trainable='none', lora_modules_to_save=[], lora_dtype='AUTO', lora_lr_ratio=None, use_rslora=False, use_dora=False, adapter_act='gelu', adapter_length=128, use_galore=False, galore_rank=128, galore_target_modules=None, galore_update_proj_gap=50, galore_scale=1.0, galore_proj_type='std', galore_optim_per_parameter=False, galore_with_embedding=False, adalora_target_r=8, adalora_init_r=12, adalora_tinit=0, adalora_tfinal=0, adalora_deltaT=1, adalora_beta1=0.85, adalora_beta2=0.85, adalora_orth_reg_weight=0.5, ia3_target_modules=['DEFAULT'], ia3_feedforward_modules=[], ia3_modules_to_save=[], llamapro_num_new_blocks=4, llamapro_num_groups=None, neftune_noise_alpha=None, neftune_backend='transformers', lisa_activated_layers=0, lisa_step_interval=20, gradient_checkpointing=True, deepspeed=None, batch_size=1, eval_batch_size=1, num_train_epochs=1, max_steps=-1, optim='adamw_torch', adam_beta1=0.9, adam_beta2=0.999, learning_rate=0.0001, weight_decay=0.1, gradient_accumulation_steps=16, max_grad_norm=0.5, predict_with_generate=False, lr_scheduler_type='linear', warmup_ratio=0.4, eval_steps=50, save_steps=50, save_only_model=False, save_total_limit=2, logging_steps=5, dataloader_num_workers=1, dataloader_pin_memory=True, push_to_hub=False, hub_model_id=None, hub_token=None, hub_private_repo=False, push_hub_strategy='push_best', test_oom_error=False, disable_tqdm=False, lazy_tokenize=False, preprocess_num_proc=1, use_flash_attn=None, ignore_args_error=False, check_model_is_latest=True, logging_dir='/home/ph/LLM2/swift/tests/llm/output/qwen-14b-chat/v1-20240506-103132/runs', report_to=['tensorboard'], acc_strategy='token', save_on_each_node=True, evaluation_strategy='steps', save_strategy='steps', save_safetensors=True, gpu_memory_fraction=None, include_num_input_tokens_seen=False, max_new_tokens=2048, do_sample=True, temperature=0.3, top_k=20, top_p=0.7, repetition_penalty=1.0, num_beams=1, per_device_train_batch_size=None, per_device_eval_batch_size=None, only_save_model=None, neftune_alpha=None, deepspeed_config_path=None, model_cache_dir=None, fsdp='', fsdp_config=None)\n",
      "[INFO:swift] Global seed set to 42\n",
      "[INFO:swift] Loading the model using model_dir: /home/ph/LLM/Qwen-14B-main/Qwen-14B-Chat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device_count: 2\n",
      "rank: -1, local_rank: -1, world_size: 1, local_world_size: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: please make sure that you are using the latest codes and checkpoints, especially if you used Qwen-7B before 09.25.2023.请使用最新模型和代码，尤其如果你在9月25日前已经开始使用Qwen-7B，千万注意不要使用错误代码和模型。\n",
      "Try importing flash-attention for faster inference...\n",
      "Warning: import flash_attn rotary fail, please install FlashAttention rotary to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/rotary\n",
      "Warning: import flash_attn rms_norm fail, please install FlashAttention layer_norm to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/layer_norm\n",
      "Warning: import flash_attn fail, please install FlashAttention to get higher efficiency https://github.com/Dao-AILab/flash-attention\n",
      "Loading checkpoint shards: 100%|██████████| 15/15 [00:07<00:00,  2.08it/s]\n",
      "[INFO:swift] registered_causal_mask to cuda\n",
      "[INFO:swift] model.max_model_len: 2048\n",
      "[INFO:swift] model_config: QWenConfig {\n",
      "  \"_name_or_path\": \"/home/ph/LLM/Qwen-14B-main/Qwen-14B-Chat\",\n",
      "  \"architectures\": [\n",
      "    \"QWenLMHeadModel\"\n",
      "  ],\n",
      "  \"attn_dropout_prob\": 0.0,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_qwen.QWenConfig\",\n",
      "    \"AutoModelForCausalLM\": \"modeling_qwen.QWenLMHeadModel\"\n",
      "  },\n",
      "  \"bf16\": true,\n",
      "  \"emb_dropout_prob\": 0.0,\n",
      "  \"fp16\": false,\n",
      "  \"fp32\": false,\n",
      "  \"hidden_size\": 5120,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 27392,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"max_position_embeddings\": 8192,\n",
      "  \"model_type\": \"qwen\",\n",
      "  \"no_bias\": true,\n",
      "  \"num_attention_heads\": 40,\n",
      "  \"num_hidden_layers\": 40,\n",
      "  \"onnx_safe\": null,\n",
      "  \"rotary_emb_base\": 10000,\n",
      "  \"rotary_pct\": 1.0,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"seq_length\": 2048,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"tokenizer_class\": \"QWenTokenizer\",\n",
      "  \"transformers_version\": \"4.40.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_cache_kernel\": false,\n",
      "  \"use_cache_quantization\": false,\n",
      "  \"use_dynamic_ntk\": true,\n",
      "  \"use_flash_attn\": true,\n",
      "  \"use_logn_attn\": true,\n",
      "  \"vocab_size\": 152064\n",
      "}\n",
      "\n",
      "[INFO:swift] generation_config: GenerationConfig {\n",
      "  \"do_sample\": true,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"max_new_tokens\": 2048,\n",
      "  \"pad_token_id\": 151645,\n",
      "  \"temperature\": 0.3,\n",
      "  \"top_k\": 20,\n",
      "  \"top_p\": 0.7\n",
      "}\n",
      "\n",
      "[INFO:swift] lora_target_modules: ['w1', 'c_attn', 'w2', 'c_proj']\n",
      "[INFO:swift] lora_modules_to_save: []\n",
      "[INFO:swift] lora_config: get_wrapped_class.<locals>.PeftWrapper(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path='/home/ph/LLM/Qwen-14B-main/Qwen-14B-Chat', revision=None, task_type='CAUSAL_LM', inference_mode=False, r=8, target_modules={'c_attn', 'w2', 'c_proj', 'w1'}, lora_alpha=32, lora_dropout=0.05, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=[], init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', loftq_config={}, use_dora=False, layer_replication=None, lora_dtype=None, lorap_lr_ratio=None, lorap_emb_lr=1e-06)\n",
      "[INFO:swift] [base_model.model.transformer.wte.weight]: requires_grad=False, dtype=torch.bfloat16, device=cuda:0\n",
      "[INFO:swift] [base_model.model.transformer.h.0.ln_1.weight]: requires_grad=False, dtype=torch.bfloat16, device=cuda:0\n",
      "[INFO:swift] [base_model.model.transformer.h.0.attn.c_attn.base_layer.weight]: requires_grad=False, dtype=torch.bfloat16, device=cuda:0\n",
      "[INFO:swift] [base_model.model.transformer.h.0.attn.c_attn.base_layer.bias]: requires_grad=False, dtype=torch.bfloat16, device=cuda:0\n",
      "[INFO:swift] [base_model.model.transformer.h.0.attn.c_attn.lora_A.default.weight]: requires_grad=True, dtype=torch.bfloat16, device=cuda:0\n",
      "[INFO:swift] [base_model.model.transformer.h.0.attn.c_attn.lora_B.default.weight]: requires_grad=True, dtype=torch.bfloat16, device=cuda:0\n",
      "[INFO:swift] [base_model.model.transformer.h.0.attn.c_proj.base_layer.weight]: requires_grad=False, dtype=torch.bfloat16, device=cuda:0\n",
      "[INFO:swift] [base_model.model.transformer.h.0.attn.c_proj.lora_A.default.weight]: requires_grad=True, dtype=torch.bfloat16, device=cuda:0\n",
      "[INFO:swift] [base_model.model.transformer.h.0.attn.c_proj.lora_B.default.weight]: requires_grad=True, dtype=torch.bfloat16, device=cuda:0\n",
      "[INFO:swift] [base_model.model.transformer.h.0.ln_2.weight]: requires_grad=False, dtype=torch.bfloat16, device=cuda:0\n",
      "[INFO:swift] [base_model.model.transformer.h.0.mlp.w1.base_layer.weight]: requires_grad=False, dtype=torch.bfloat16, device=cuda:0\n",
      "[INFO:swift] [base_model.model.transformer.h.0.mlp.w1.lora_A.default.weight]: requires_grad=True, dtype=torch.bfloat16, device=cuda:0\n",
      "[INFO:swift] [base_model.model.transformer.h.0.mlp.w1.lora_B.default.weight]: requires_grad=True, dtype=torch.bfloat16, device=cuda:0\n",
      "[INFO:swift] [base_model.model.transformer.h.0.mlp.w2.base_layer.weight]: requires_grad=False, dtype=torch.bfloat16, device=cuda:0\n",
      "[INFO:swift] [base_model.model.transformer.h.0.mlp.w2.lora_A.default.weight]: requires_grad=True, dtype=torch.bfloat16, device=cuda:0\n",
      "[INFO:swift] [base_model.model.transformer.h.0.mlp.w2.lora_B.default.weight]: requires_grad=True, dtype=torch.bfloat16, device=cuda:0\n",
      "[INFO:swift] [base_model.model.transformer.h.0.mlp.c_proj.base_layer.weight]: requires_grad=False, dtype=torch.bfloat16, device=cuda:0\n",
      "[INFO:swift] [base_model.model.transformer.h.0.mlp.c_proj.lora_A.default.weight]: requires_grad=True, dtype=torch.bfloat16, device=cuda:0\n",
      "[INFO:swift] [base_model.model.transformer.h.0.mlp.c_proj.lora_B.default.weight]: requires_grad=True, dtype=torch.bfloat16, device=cuda:0\n",
      "[INFO:swift] [base_model.model.transformer.h.1.ln_1.weight]: requires_grad=False, dtype=torch.bfloat16, device=cuda:0\n",
      "[INFO:swift] ...\n",
      "[INFO:swift] PeftModelForCausalLM(\n",
      "  (base_model): LoraModel(\n",
      "    (model): QWenLMHeadModel(\n",
      "      (transformer): QWenModel(\n",
      "        (wte): Embedding(152064, 5120)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "        (rotary_emb): RotaryEmbedding()\n",
      "        (h): ModuleList(\n",
      "          (0-39): 40 x QWenBlock(\n",
      "            (ln_1): RMSNorm()\n",
      "            (attn): QWenAttention(\n",
      "              (c_attn): lora.Linear(\n",
      "                (base_layer): Linear(in_features=5120, out_features=15360, bias=True)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=5120, out_features=8, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=8, out_features=15360, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (c_proj): lora.Linear(\n",
      "                (base_layer): Linear(in_features=5120, out_features=5120, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=5120, out_features=8, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=8, out_features=5120, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (attn_dropout): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ln_2): RMSNorm()\n",
      "            (mlp): QWenMLP(\n",
      "              (w1): lora.Linear(\n",
      "                (base_layer): Linear(in_features=5120, out_features=13696, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=5120, out_features=8, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=8, out_features=13696, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (w2): lora.Linear(\n",
      "                (base_layer): Linear(in_features=5120, out_features=13696, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=5120, out_features=8, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=8, out_features=13696, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (c_proj): lora.Linear(\n",
      "                (base_layer): Linear(in_features=13696, out_features=5120, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=13696, out_features=8, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=8, out_features=5120, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (ln_f): RMSNorm()\n",
      "      )\n",
      "      (lm_head): Linear(in_features=5120, out_features=152064, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "[INFO:swift] PeftModelForCausalLM: 14195.1846M Params (27.8938M Trainable [0.1965%]), 68.4196M Buffers.\n",
      "[INFO:swift] Setting model.config.use_cache: False\n",
      "[INFO:swift] Downloading the dataset from ModelScope, dataset_id: AI-ModelScope/sharegpt_gpt4\n",
      "[WARNING:modelscope] Authentication has expired, please re-login if you need to access private models or datasets.\n",
      "[WARNING:modelscope] Authentication has expired, please re-login if you need to access private models or datasets.\n",
      "[WARNING:modelscope] Authentication has expired, please re-login if you need to access private models or datasets.\n",
      "[WARNING:modelscope] Reusing dataset dataset_builder (/home/ph/.cache/modelscope/hub/datasets/AI-ModelScope/sharegpt_gpt4/master/data_files)\n",
      "[INFO:modelscope] Generating dataset dataset_builder (/home/ph/.cache/modelscope/hub/datasets/AI-ModelScope/sharegpt_gpt4/master/data_files)\n",
      "[INFO:modelscope] Reusing cached meta-data file: /home/ph/.cache/modelscope/hub/datasets/AI-ModelScope/sharegpt_gpt4/master/data_files/fb0d36e5a0143e6e20fb90c75365f995\n",
      "[WARNING:modelscope] Authentication has expired, please re-login if you need to access private models or datasets.\n",
      "100%|██████████| 6206/6206 [00:02<00:00, 2149.89it/s]\n",
      "[INFO:swift] train_dataset_sample: 1000\n",
      "[INFO:swift] val_dataset_sample: 10\n",
      "[INFO:swift] train_dataset: Dataset({\n",
      "    features: ['history', 'query', 'response'],\n",
      "    num_rows: 1500\n",
      "})\n",
      "[INFO:swift] val_dataset: Dataset({\n",
      "    features: ['history', 'query', 'response'],\n",
      "    num_rows: 10\n",
      "})\n",
      "[INFO:swift] system: You are a helpful assistant.\n",
      "[INFO:swift] args.lazy_tokenize: False\n",
      "[INFO:swift] Using num_proc: 1\n",
      " 31%|███▏      | 471/1500 [00:02<00:05, 173.28it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (10655 > 8192). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 1500/1500 [00:05<00:00, 287.08it/s] \n",
      "100%|██████████| 10/10 [00:00<00:00, 279.92it/s]\n",
      "[INFO:swift] [INPUT_IDS] [151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 35127, 752, 279, 821, 1614, 369, 264, 31783, 2025, 3118, 389, 821, 20767, 13851, 291, 11211, 151645, 198, 151644, 77091, 198, 32, 31783, 2025, 3118, 389, 821, 20767, 13851, 291, 11211, 646, 28066, 264, 10601, 315, 389, 65186, 323, 1007, 65186, 821, 311, 10091, 323, 3754, 6002, 21880, 11, 21160, 11, 323, 2518, 336, 1300, 13, 5692, 374, 264, 11827, 821, 1614, 429, 40155, 7565, 14744, 323, 862, 11871, 1447, 16, 13, 2657, 510, 197, 9, 1196, 75738, 307, 320, 9587, 12816, 340, 197, 9, 1156, 75738, 606, 198, 197, 9, 1537, 75738, 606, 198, 197, 9, 2551, 198, 197, 9, 4540, 75738, 4082, 198, 197, 9, 2400, 75738, 1055, 75738, 27713, 198, 197, 9, 12227, 75738, 1028, 198, 197, 9, 2621, 320, 12807, 340, 17, 13, 9660, 510, 197, 9, 3950, 75738, 307, 320, 9587, 12816, 340, 197, 9, 3950, 75738, 606, 198, 197, 9, 3950, 75738, 18785, 198, 197, 9, 2790, 75738, 94683, 198, 197, 9, 58328, 198, 197, 9, 7785, 75738, 20257, 75738, 4995, 198, 18, 13, 36483, 510, 197, 9, 15085, 75738, 307, 320, 9587, 12816, 340, 197, 9, 1196, 75738, 307, 320, 28443, 1376, 11, 5435, 311, 2657, 340, 197, 9, 584, 75738, 792, 198, 197, 9, 869, 75738, 792, 320, 36444, 340, 19, 13, 9660, 21190, 510, 197, 9, 3950, 75738, 21571, 75738, 307, 320, 9587, 12816, 340, 197, 9, 15085, 75738, 307, 320, 28443, 1376, 11, 5435, 311, 36483, 340, 197, 9, 3950, 75738, 307, 320, 28443, 1376, 11, 5435, 311, 9660, 340, 197, 9, 8172, 198, 20, 13, 17869, 510, 197, 9, 7745, 75738, 307, 320, 9587, 12816, 340, 197, 9, 4646, 75738, 35735, 75738, 307, 320, 28443, 1376, 11, 5435, 311, 36483, 340, 197, 9, 13964, 75738, 35735, 75738, 307, 320, 28443, 1376, 11, 5435, 311, 36483, 340, 197, 9, 3950, 75738, 307, 320, 28443, 1376, 11, 5435, 311, 9660, 340, 197, 9, 3311, 198, 197, 9, 7745, 75738, 30017, 198, 197, 9, 11441, 198, 197, 9, 7745, 75738, 8296, 198, 197, 9, 2639, 320, 28210, 11, 2393, 11, 4641, 340, 21, 13, 55800, 510, 197, 9, 11313, 75738, 307, 320, 9587, 12816, 340, 197, 9, 3950, 75738, 307, 320, 28443, 1376, 11, 5435, 311, 9660, 340, 197, 9, 11313, 75738, 606, 198, 197, 9, 4008, 198, 197, 9, 2567, 75738, 30566, 198, 197, 9, 11313, 75738, 1805, 320, 12807, 340, 197, 9, 1191, 75738, 1028, 198, 197, 9, 835, 75738, 1028, 198, 22, 13, 55800, 6033, 33106, 510, 197, 9, 55652, 75738, 307, 320, 9587, 12816, 340, 197, 9, 1196, 75738, 307, 320, 28443, 1376, 11, 5435, 311, 2657, 340, 197, 9, 11313, 75738, 307, 320, 28443, 1376, 11, 5435, 311, 55800, 340, 197, 9, 55652, 75738, 1028, 198, 197, 9, 2639, 320, 28210, 11, 2393, 11, 4641, 340, 23, 13, 55399, 510, 197, 9, 29238, 75738, 307, 320, 9587, 12816, 340, 197, 9, 29238, 75738, 606, 198, 197, 9, 2551, 198, 197, 9, 4540, 75738, 4082, 198, 197, 9, 2621, 198, 24, 13, 55399, 3323, 78316, 510, 197, 9, 23757, 75738, 307, 320, 9587, 12816, 340, 197, 9, 29238, 75738, 307, 320, 28443, 1376, 11, 5435, 311, 55399, 340, 197, 9, 3950, 75738, 307, 320, 28443, 1376, 11, 5435, 311, 9660, 340, 197, 9, 23757, 75738, 6045, 198, 197, 9, 1191, 75738, 1028, 198, 197, 9, 835, 75738, 1028, 271, 1986, 821, 1614, 40155, 279, 6028, 14744, 6398, 304, 264, 821, 20767, 13851, 291, 3950, 5980, 31783, 2025, 11, 2670, 3847, 11, 11211, 11, 53308, 11, 14131, 11, 21160, 11, 2518, 336, 1300, 11, 323, 41770, 13, 1446, 646, 4623, 9225, 323, 5602, 279, 1614, 311, 32335, 5107, 4419, 476, 8502, 3151, 311, 697, 990, 1142, 13, 151645, 198, 151644, 872, 198, 35127, 752, 264, 738, 315, 97723, 311, 10091, 279, 3403, 821, 1614, 151645, 198, 151644, 77091, 198, 8420, 374, 264, 738, 315, 25414, 1262, 5333, 36342, 311, 10091, 279, 821, 1614, 9733, 3403, 13, 4220, 36342, 686, 2138, 498, 311, 2736, 64133, 320, 4021, 11, 4457, 11, 5549, 11, 10428, 8, 7525, 389, 279, 14744, 382, 1474, 1447, 9, 12869, 608, 4218, 25, 4230, 264, 501, 1196, 624, 9, 7890, 608, 4218, 25, 31562, 264, 1140, 315, 3847, 624, 9, 7890, 608, 4218, 9388, 872, 75738, 307, 16097, 31562, 264, 3151, 1196, 553, 1196, 75738, 307, 624, 9, 34380, 608, 4218, 9388, 872, 75738, 307, 16097, 5549, 264, 3151, 1196, 594, 1995, 624, 9, 17197, 608, 4218, 9388, 872, 75738, 307, 16097, 10428, 264, 3151, 1196, 382, 3323, 1447, 9, 12869, 608, 30566, 25, 4230, 264, 501, 3950, 624, 9, 7890, 608, 30566, 25, 31562, 264, 1140, 315, 11211, 624, 9, 7890, 608, 30566, 9388, 5839, 75738, 307, 16097, 31562, 264, 3151, 3950, 553, 3950, 75738, 307, 624, 9, 34380, 608, 30566, 9388, 5839, 75738, 307, 16097, 5549, 264, 3151, 3950, 594, 1995, 624, 9, 17197, 608, 30566, 9388, 5839, 75738, 307, 16097, 10428, 264, 3151, 3950, 382, 38259, 1447, 9, 12869, 608, 35735, 82, 25, 4230, 264, 501, 15085, 624, 9, 7890, 608, 35735, 82, 25, 31562, 264, 1140, 315, 53308, 624, 9, 7890, 608, 35735, 82, 9388, 35735, 75738, 307, 16097, 31562, 264, 3151, 15085, 553, 15085, 75738, 307, 624, 9, 34380, 608, 35735, 82, 9388, 35735, 75738, 307, 16097, 5549, 264, 3151, 15085, 594, 1995, 624, 9, 17197, 608, 35735, 82, 9388, 35735, 75738, 307, 16097, 10428, 264, 3151, 15085, 382, 3323, 21190, 1447, 9, 12869, 608, 5839, 83125, 3020, 25, 4230, 264, 501, 3950, 8172, 624, 9, 7890, 608, 5839, 83125, 3020, 25, 31562, 264, 1140, 315, 3950, 38854, 624, 9, 7890, 608, 5839, 83125, 3020, 9388, 5839, 75738, 21571, 75738, 307, 16097, 31562, 264, 3151, 3950, 8172, 553, 3950, 75738, 21571, 75738, 307, 624, 9, 34380, 608, 5839, 83125, 3020, 9388, 5839, 75738, 21571, 75738, 307, 16097, 5549, 264, 3151, 3950, 8172, 594, 1995, 624, 9, 17197, 608, 5839, 83125, 3020, 9388, 5839, 75738, 21571, 75738, 307, 16097, 10428, 264, 3151, 3950, 8172, 382, 8070, 1447, 9, 12869, 608, 41844, 25, 4230, 264, 501, 7745, 624, 9, 7890, 608, 41844, 25, 31562, 264, 1140, 315, 14131, 624, 9, 7890, 608, 41844, 9388, 13528, 75738, 307, 16097, 31562, 264, 3151, 7745, 553, 7745, 75738, 307, 624, 9, 34380, 608, 41844, 9388, 13528, 75738, 307, 16097, 5549, 264, 3151, 7745, 594, 1995, 382, 59622, 1447, 9, 12869, 608, 265, 4014, 25, 4230, 264, 501, 11313, 624, 9, 7890, 608, 265, 4014, 25, 31562, 264, 1140, 315, 21160, 624, 9, 7890, 608, 265, 4014, 9388, 49007, 75738, 307, 16097, 31562, 264, 3151, 11313, 553, 11313, 75738, 307, 624, 9, 34380, 608, 265, 4014, 9388, 49007, 75738, 307, 16097, 5549, 264, 3151, 11313, 594, 1995, 624, 9, 17197, 608, 265, 4014, 9388, 49007, 75738, 307, 16097, 10428, 264, 3151, 11313, 382, 59622, 6033, 33106, 1447, 9, 12869, 608, 49007, 31598, 336, 1300, 25, 4230, 264, 501, 11313, 55652, 624, 9, 7890, 608, 49007, 31598, 336, 1300, 25, 31562, 264, 1140, 315, 11313, 2518, 336, 1300, 624, 9, 7890, 608, 49007, 31598, 336, 1300, 9388, 1151, 33106, 75738, 307, 16097, 31562, 264, 3151, 11313, 55652, 553, 55652, 75738, 307, 624, 9, 34380, 608, 49007, 31598, 336, 1300, 9388, 1151, 33106, 75738, 307, 16097, 5549, 264, 3151, 11313, 55652, 594, 1995, 624, 9, 17197, 608, 49007, 31598, 336, 1300, 9388, 1151, 33106, 75738, 307, 16097, 10428, 264, 3151, 11313, 55652, 382, 84545, 1447, 9, 12869, 608, 1174, 98806, 25, 4230, 264, 501, 29238, 624, 9, 7890, 608, 1174, 98806, 25, 31562, 264, 1140, 315, 41770, 624, 9, 7890, 608, 1174, 98806, 9388, 39011, 75738, 307, 16097, 31562, 264, 3151, 29238, 553, 29238, 75738, 307, 624, 9, 34380, 608, 1174, 98806, 9388, 39011, 75738, 307, 16097, 5549, 264, 3151, 29238, 594, 1995, 624, 9, 17197, 608, 1174, 98806, 9388, 39011, 75738, 307, 16097, 10428, 264, 3151, 29238, 382, 84545, 3323, 78316, 1447, 9, 12869, 608, 39011, 34841, 12, 4742, 804, 25, 4230, 264, 501, 29238, 3950, 23757, 624, 9, 7890, 608, 39011, 34841, 12, 4742, 804, 25, 31562, 264, 1140, 315, 29238, 3950, 69642, 624, 9, 7890, 608, 39011, 34841, 12, 4742, 804, 9388, 93239, 75738, 307, 16097, 31562, 264, 3151, 29238, 3950, 23757, 553, 23757, 75738, 307, 624, 9, 34380, 608, 39011, 34841, 12, 4742, 804, 9388, 93239, 75738, 307, 16097, 5549, 264, 3151, 29238, 3950, 23757, 594, 1995, 624, 9, 17197, 608, 39011, 34841, 12, 4742, 804, 9388, 93239, 75738, 307, 16097, 10428, 264, 3151, 29238, 3950, 23757, 382, 9485, 5333, 36342, 1265, 3410, 264, 6437, 16266, 369, 18150, 279, 821, 1614, 315, 264, 821, 20767, 13851, 291, 3950, 5980, 31783, 2025, 13, 1446, 646, 9225, 476, 5602, 1493, 36342, 438, 4362, 311, 27968, 311, 3151, 8502, 476, 5107, 4419, 13, 151645]\n",
      "[INFO:swift] [INPUT] <|im_start|>system\n",
      "You are a helpful assistant.<|im_end|>\n",
      "<|im_start|>user\n",
      "Give me the data model for a loyalty program based on data-enriched tokens<|im_end|>\n",
      "<|im_start|>assistant\n",
      "A loyalty program based on data-enriched tokens can utilize a combination of on-chain and off-chain data to manage and track customer interactions, rewards, and redemptions. Here is a suggested data model that captures essential entities and their relationships:\n",
      "\n",
      "1. User:\n",
      "\t* user\\_id (unique identifier)\n",
      "\t* first\\_name\n",
      "\t* last\\_name\n",
      "\t* email\n",
      "\t* phone\\_number\n",
      "\t* date\\_of\\_birth\n",
      "\t* registration\\_date\n",
      "\t* address (optional)\n",
      "2. Token:\n",
      "\t* token\\_id (unique identifier)\n",
      "\t* token\\_name\n",
      "\t* token\\_symbol\n",
      "\t* total\\_supply\n",
      "\t* decimals\n",
      "\t* smart\\_contract\\_address\n",
      "3. Wallet:\n",
      "\t* wallet\\_id (unique identifier)\n",
      "\t* user\\_id (foreign key, related to User)\n",
      "\t* public\\_key\n",
      "\t* private\\_key (encrypted)\n",
      "4. TokenBalance:\n",
      "\t* token\\_balance\\_id (unique identifier)\n",
      "\t* wallet\\_id (foreign key, related to Wallet)\n",
      "\t* token\\_id (foreign key, related to Token)\n",
      "\t* balance\n",
      "5. Transaction:\n",
      "\t* transaction\\_id (unique identifier)\n",
      "\t* sender\\_wallet\\_id (foreign key, related to Wallet)\n",
      "\t* receiver\\_wallet\\_id (foreign key, related to Wallet)\n",
      "\t* token\\_id (foreign key, related to Token)\n",
      "\t* amount\n",
      "\t* transaction\\_fee\n",
      "\t* timestamp\n",
      "\t* transaction\\_hash\n",
      "\t* status (pending, success, failed)\n",
      "6. Reward:\n",
      "\t* reward\\_id (unique identifier)\n",
      "\t* token\\_id (foreign key, related to Token)\n",
      "\t* reward\\_name\n",
      "\t* description\n",
      "\t* required\\_tokens\n",
      "\t* reward\\_image (optional)\n",
      "\t* start\\_date\n",
      "\t* end\\_date\n",
      "7. RewardRedemption:\n",
      "\t* redemption\\_id (unique identifier)\n",
      "\t* user\\_id (foreign key, related to User)\n",
      "\t* reward\\_id (foreign key, related to Reward)\n",
      "\t* redemption\\_date\n",
      "\t* status (pending, success, failed)\n",
      "8. Merchant:\n",
      "\t* merchant\\_id (unique identifier)\n",
      "\t* merchant\\_name\n",
      "\t* email\n",
      "\t* phone\\_number\n",
      "\t* address\n",
      "9. MerchantTokenAllocation:\n",
      "\t* allocation\\_id (unique identifier)\n",
      "\t* merchant\\_id (foreign key, related to Merchant)\n",
      "\t* token\\_id (foreign key, related to Token)\n",
      "\t* allocation\\_amount\n",
      "\t* start\\_date\n",
      "\t* end\\_date\n",
      "\n",
      "This data model captures the primary entities involved in a data-enriched token-based loyalty program, including users, tokens, wallets, transactions, rewards, redemptions, and merchants. You can further expand and modify the model to incorporate additional features or requirements specific to your use case.<|im_end|>\n",
      "<|im_start|>user\n",
      "Give me a set of apis to manage the above data model<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Here is a set of RESTful API endpoints to manage the data model mentioned above. These endpoints will allow you to perform CRUD (Create, Read, Update, Delete) operations on the entities.\n",
      "\n",
      "User:\n",
      "\n",
      "* POST /users: Create a new user.\n",
      "* GET /users: Retrieve a list of users.\n",
      "* GET /users/{user\\_id}: Retrieve a specific user by user\\_id.\n",
      "* PUT /users/{user\\_id}: Update a specific user's information.\n",
      "* DELETE /users/{user\\_id}: Delete a specific user.\n",
      "\n",
      "Token:\n",
      "\n",
      "* POST /tokens: Create a new token.\n",
      "* GET /tokens: Retrieve a list of tokens.\n",
      "* GET /tokens/{token\\_id}: Retrieve a specific token by token\\_id.\n",
      "* PUT /tokens/{token\\_id}: Update a specific token's information.\n",
      "* DELETE /tokens/{token\\_id}: Delete a specific token.\n",
      "\n",
      "Wallet:\n",
      "\n",
      "* POST /wallets: Create a new wallet.\n",
      "* GET /wallets: Retrieve a list of wallets.\n",
      "* GET /wallets/{wallet\\_id}: Retrieve a specific wallet by wallet\\_id.\n",
      "* PUT /wallets/{wallet\\_id}: Update a specific wallet's information.\n",
      "* DELETE /wallets/{wallet\\_id}: Delete a specific wallet.\n",
      "\n",
      "TokenBalance:\n",
      "\n",
      "* POST /token-balances: Create a new token balance.\n",
      "* GET /token-balances: Retrieve a list of token balances.\n",
      "* GET /token-balances/{token\\_balance\\_id}: Retrieve a specific token balance by token\\_balance\\_id.\n",
      "* PUT /token-balances/{token\\_balance\\_id}: Update a specific token balance's information.\n",
      "* DELETE /token-balances/{token\\_balance\\_id}: Delete a specific token balance.\n",
      "\n",
      "Transaction:\n",
      "\n",
      "* POST /transactions: Create a new transaction.\n",
      "* GET /transactions: Retrieve a list of transactions.\n",
      "* GET /transactions/{transaction\\_id}: Retrieve a specific transaction by transaction\\_id.\n",
      "* PUT /transactions/{transaction\\_id}: Update a specific transaction's information.\n",
      "\n",
      "Reward:\n",
      "\n",
      "* POST /rewards: Create a new reward.\n",
      "* GET /rewards: Retrieve a list of rewards.\n",
      "* GET /rewards/{reward\\_id}: Retrieve a specific reward by reward\\_id.\n",
      "* PUT /rewards/{reward\\_id}: Update a specific reward's information.\n",
      "* DELETE /rewards/{reward\\_id}: Delete a specific reward.\n",
      "\n",
      "RewardRedemption:\n",
      "\n",
      "* POST /reward-redemptions: Create a new reward redemption.\n",
      "* GET /reward-redemptions: Retrieve a list of reward redemptions.\n",
      "* GET /reward-redemptions/{redemption\\_id}: Retrieve a specific reward redemption by redemption\\_id.\n",
      "* PUT /reward-redemptions/{redemption\\_id}: Update a specific reward redemption's information.\n",
      "* DELETE /reward-redemptions/{redemption\\_id}: Delete a specific reward redemption.\n",
      "\n",
      "Merchant:\n",
      "\n",
      "* POST /merchants: Create a new merchant.\n",
      "* GET /merchants: Retrieve a list of merchants.\n",
      "* GET /merchants/{merchant\\_id}: Retrieve a specific merchant by merchant\\_id.\n",
      "* PUT /merchants/{merchant\\_id}: Update a specific merchant's information.\n",
      "* DELETE /merchants/{merchant\\_id}: Delete a specific merchant.\n",
      "\n",
      "MerchantTokenAllocation:\n",
      "\n",
      "* POST /merchant-token-allocations: Create a new merchant token allocation.\n",
      "* GET /merchant-token-allocations: Retrieve a list of merchant token allocations.\n",
      "* GET /merchant-token-allocations/{allocation\\_id}: Retrieve a specific merchant token allocation by allocation\\_id.\n",
      "* PUT /merchant-token-allocations/{allocation\\_id}: Update a specific merchant token allocation's information.\n",
      "* DELETE /merchant-token-allocations/{allocation\\_id}: Delete a specific merchant token allocation.\n",
      "\n",
      "These API endpoints should provide a solid foundation for managing the data model of a data-enriched token-based loyalty program. You can expand or modify these endpoints as needed to cater to specific requirements or additional features.<|im_end|>\n",
      "[INFO:swift] [LABLES_IDS] [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 32, 31783, 2025, 3118, 389, 821, 20767, 13851, 291, 11211, 646, 28066, 264, 10601, 315, 389, 65186, 323, 1007, 65186, 821, 311, 10091, 323, 3754, 6002, 21880, 11, 21160, 11, 323, 2518, 336, 1300, 13, 5692, 374, 264, 11827, 821, 1614, 429, 40155, 7565, 14744, 323, 862, 11871, 1447, 16, 13, 2657, 510, 197, 9, 1196, 75738, 307, 320, 9587, 12816, 340, 197, 9, 1156, 75738, 606, 198, 197, 9, 1537, 75738, 606, 198, 197, 9, 2551, 198, 197, 9, 4540, 75738, 4082, 198, 197, 9, 2400, 75738, 1055, 75738, 27713, 198, 197, 9, 12227, 75738, 1028, 198, 197, 9, 2621, 320, 12807, 340, 17, 13, 9660, 510, 197, 9, 3950, 75738, 307, 320, 9587, 12816, 340, 197, 9, 3950, 75738, 606, 198, 197, 9, 3950, 75738, 18785, 198, 197, 9, 2790, 75738, 94683, 198, 197, 9, 58328, 198, 197, 9, 7785, 75738, 20257, 75738, 4995, 198, 18, 13, 36483, 510, 197, 9, 15085, 75738, 307, 320, 9587, 12816, 340, 197, 9, 1196, 75738, 307, 320, 28443, 1376, 11, 5435, 311, 2657, 340, 197, 9, 584, 75738, 792, 198, 197, 9, 869, 75738, 792, 320, 36444, 340, 19, 13, 9660, 21190, 510, 197, 9, 3950, 75738, 21571, 75738, 307, 320, 9587, 12816, 340, 197, 9, 15085, 75738, 307, 320, 28443, 1376, 11, 5435, 311, 36483, 340, 197, 9, 3950, 75738, 307, 320, 28443, 1376, 11, 5435, 311, 9660, 340, 197, 9, 8172, 198, 20, 13, 17869, 510, 197, 9, 7745, 75738, 307, 320, 9587, 12816, 340, 197, 9, 4646, 75738, 35735, 75738, 307, 320, 28443, 1376, 11, 5435, 311, 36483, 340, 197, 9, 13964, 75738, 35735, 75738, 307, 320, 28443, 1376, 11, 5435, 311, 36483, 340, 197, 9, 3950, 75738, 307, 320, 28443, 1376, 11, 5435, 311, 9660, 340, 197, 9, 3311, 198, 197, 9, 7745, 75738, 30017, 198, 197, 9, 11441, 198, 197, 9, 7745, 75738, 8296, 198, 197, 9, 2639, 320, 28210, 11, 2393, 11, 4641, 340, 21, 13, 55800, 510, 197, 9, 11313, 75738, 307, 320, 9587, 12816, 340, 197, 9, 3950, 75738, 307, 320, 28443, 1376, 11, 5435, 311, 9660, 340, 197, 9, 11313, 75738, 606, 198, 197, 9, 4008, 198, 197, 9, 2567, 75738, 30566, 198, 197, 9, 11313, 75738, 1805, 320, 12807, 340, 197, 9, 1191, 75738, 1028, 198, 197, 9, 835, 75738, 1028, 198, 22, 13, 55800, 6033, 33106, 510, 197, 9, 55652, 75738, 307, 320, 9587, 12816, 340, 197, 9, 1196, 75738, 307, 320, 28443, 1376, 11, 5435, 311, 2657, 340, 197, 9, 11313, 75738, 307, 320, 28443, 1376, 11, 5435, 311, 55800, 340, 197, 9, 55652, 75738, 1028, 198, 197, 9, 2639, 320, 28210, 11, 2393, 11, 4641, 340, 23, 13, 55399, 510, 197, 9, 29238, 75738, 307, 320, 9587, 12816, 340, 197, 9, 29238, 75738, 606, 198, 197, 9, 2551, 198, 197, 9, 4540, 75738, 4082, 198, 197, 9, 2621, 198, 24, 13, 55399, 3323, 78316, 510, 197, 9, 23757, 75738, 307, 320, 9587, 12816, 340, 197, 9, 29238, 75738, 307, 320, 28443, 1376, 11, 5435, 311, 55399, 340, 197, 9, 3950, 75738, 307, 320, 28443, 1376, 11, 5435, 311, 9660, 340, 197, 9, 23757, 75738, 6045, 198, 197, 9, 1191, 75738, 1028, 198, 197, 9, 835, 75738, 1028, 271, 1986, 821, 1614, 40155, 279, 6028, 14744, 6398, 304, 264, 821, 20767, 13851, 291, 3950, 5980, 31783, 2025, 11, 2670, 3847, 11, 11211, 11, 53308, 11, 14131, 11, 21160, 11, 2518, 336, 1300, 11, 323, 41770, 13, 1446, 646, 4623, 9225, 323, 5602, 279, 1614, 311, 32335, 5107, 4419, 476, 8502, 3151, 311, 697, 990, 1142, 13, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 8420, 374, 264, 738, 315, 25414, 1262, 5333, 36342, 311, 10091, 279, 821, 1614, 9733, 3403, 13, 4220, 36342, 686, 2138, 498, 311, 2736, 64133, 320, 4021, 11, 4457, 11, 5549, 11, 10428, 8, 7525, 389, 279, 14744, 382, 1474, 1447, 9, 12869, 608, 4218, 25, 4230, 264, 501, 1196, 624, 9, 7890, 608, 4218, 25, 31562, 264, 1140, 315, 3847, 624, 9, 7890, 608, 4218, 9388, 872, 75738, 307, 16097, 31562, 264, 3151, 1196, 553, 1196, 75738, 307, 624, 9, 34380, 608, 4218, 9388, 872, 75738, 307, 16097, 5549, 264, 3151, 1196, 594, 1995, 624, 9, 17197, 608, 4218, 9388, 872, 75738, 307, 16097, 10428, 264, 3151, 1196, 382, 3323, 1447, 9, 12869, 608, 30566, 25, 4230, 264, 501, 3950, 624, 9, 7890, 608, 30566, 25, 31562, 264, 1140, 315, 11211, 624, 9, 7890, 608, 30566, 9388, 5839, 75738, 307, 16097, 31562, 264, 3151, 3950, 553, 3950, 75738, 307, 624, 9, 34380, 608, 30566, 9388, 5839, 75738, 307, 16097, 5549, 264, 3151, 3950, 594, 1995, 624, 9, 17197, 608, 30566, 9388, 5839, 75738, 307, 16097, 10428, 264, 3151, 3950, 382, 38259, 1447, 9, 12869, 608, 35735, 82, 25, 4230, 264, 501, 15085, 624, 9, 7890, 608, 35735, 82, 25, 31562, 264, 1140, 315, 53308, 624, 9, 7890, 608, 35735, 82, 9388, 35735, 75738, 307, 16097, 31562, 264, 3151, 15085, 553, 15085, 75738, 307, 624, 9, 34380, 608, 35735, 82, 9388, 35735, 75738, 307, 16097, 5549, 264, 3151, 15085, 594, 1995, 624, 9, 17197, 608, 35735, 82, 9388, 35735, 75738, 307, 16097, 10428, 264, 3151, 15085, 382, 3323, 21190, 1447, 9, 12869, 608, 5839, 83125, 3020, 25, 4230, 264, 501, 3950, 8172, 624, 9, 7890, 608, 5839, 83125, 3020, 25, 31562, 264, 1140, 315, 3950, 38854, 624, 9, 7890, 608, 5839, 83125, 3020, 9388, 5839, 75738, 21571, 75738, 307, 16097, 31562, 264, 3151, 3950, 8172, 553, 3950, 75738, 21571, 75738, 307, 624, 9, 34380, 608, 5839, 83125, 3020, 9388, 5839, 75738, 21571, 75738, 307, 16097, 5549, 264, 3151, 3950, 8172, 594, 1995, 624, 9, 17197, 608, 5839, 83125, 3020, 9388, 5839, 75738, 21571, 75738, 307, 16097, 10428, 264, 3151, 3950, 8172, 382, 8070, 1447, 9, 12869, 608, 41844, 25, 4230, 264, 501, 7745, 624, 9, 7890, 608, 41844, 25, 31562, 264, 1140, 315, 14131, 624, 9, 7890, 608, 41844, 9388, 13528, 75738, 307, 16097, 31562, 264, 3151, 7745, 553, 7745, 75738, 307, 624, 9, 34380, 608, 41844, 9388, 13528, 75738, 307, 16097, 5549, 264, 3151, 7745, 594, 1995, 382, 59622, 1447, 9, 12869, 608, 265, 4014, 25, 4230, 264, 501, 11313, 624, 9, 7890, 608, 265, 4014, 25, 31562, 264, 1140, 315, 21160, 624, 9, 7890, 608, 265, 4014, 9388, 49007, 75738, 307, 16097, 31562, 264, 3151, 11313, 553, 11313, 75738, 307, 624, 9, 34380, 608, 265, 4014, 9388, 49007, 75738, 307, 16097, 5549, 264, 3151, 11313, 594, 1995, 624, 9, 17197, 608, 265, 4014, 9388, 49007, 75738, 307, 16097, 10428, 264, 3151, 11313, 382, 59622, 6033, 33106, 1447, 9, 12869, 608, 49007, 31598, 336, 1300, 25, 4230, 264, 501, 11313, 55652, 624, 9, 7890, 608, 49007, 31598, 336, 1300, 25, 31562, 264, 1140, 315, 11313, 2518, 336, 1300, 624, 9, 7890, 608, 49007, 31598, 336, 1300, 9388, 1151, 33106, 75738, 307, 16097, 31562, 264, 3151, 11313, 55652, 553, 55652, 75738, 307, 624, 9, 34380, 608, 49007, 31598, 336, 1300, 9388, 1151, 33106, 75738, 307, 16097, 5549, 264, 3151, 11313, 55652, 594, 1995, 624, 9, 17197, 608, 49007, 31598, 336, 1300, 9388, 1151, 33106, 75738, 307, 16097, 10428, 264, 3151, 11313, 55652, 382, 84545, 1447, 9, 12869, 608, 1174, 98806, 25, 4230, 264, 501, 29238, 624, 9, 7890, 608, 1174, 98806, 25, 31562, 264, 1140, 315, 41770, 624, 9, 7890, 608, 1174, 98806, 9388, 39011, 75738, 307, 16097, 31562, 264, 3151, 29238, 553, 29238, 75738, 307, 624, 9, 34380, 608, 1174, 98806, 9388, 39011, 75738, 307, 16097, 5549, 264, 3151, 29238, 594, 1995, 624, 9, 17197, 608, 1174, 98806, 9388, 39011, 75738, 307, 16097, 10428, 264, 3151, 29238, 382, 84545, 3323, 78316, 1447, 9, 12869, 608, 39011, 34841, 12, 4742, 804, 25, 4230, 264, 501, 29238, 3950, 23757, 624, 9, 7890, 608, 39011, 34841, 12, 4742, 804, 25, 31562, 264, 1140, 315, 29238, 3950, 69642, 624, 9, 7890, 608, 39011, 34841, 12, 4742, 804, 9388, 93239, 75738, 307, 16097, 31562, 264, 3151, 29238, 3950, 23757, 553, 23757, 75738, 307, 624, 9, 34380, 608, 39011, 34841, 12, 4742, 804, 9388, 93239, 75738, 307, 16097, 5549, 264, 3151, 29238, 3950, 23757, 594, 1995, 624, 9, 17197, 608, 39011, 34841, 12, 4742, 804, 9388, 93239, 75738, 307, 16097, 10428, 264, 3151, 29238, 3950, 23757, 382, 9485, 5333, 36342, 1265, 3410, 264, 6437, 16266, 369, 18150, 279, 821, 1614, 315, 264, 821, 20767, 13851, 291, 3950, 5980, 31783, 2025, 13, 1446, 646, 9225, 476, 5602, 1493, 36342, 438, 4362, 311, 27968, 311, 3151, 8502, 476, 5107, 4419, 13, 151645]\n",
      "[INFO:swift] [LABLES] [-100 * 35]A loyalty program based on data-enriched tokens can utilize a combination of on-chain and off-chain data to manage and track customer interactions, rewards, and redemptions. Here is a suggested data model that captures essential entities and their relationships:\n",
      "\n",
      "1. User:\n",
      "\t* user\\_id (unique identifier)\n",
      "\t* first\\_name\n",
      "\t* last\\_name\n",
      "\t* email\n",
      "\t* phone\\_number\n",
      "\t* date\\_of\\_birth\n",
      "\t* registration\\_date\n",
      "\t* address (optional)\n",
      "2. Token:\n",
      "\t* token\\_id (unique identifier)\n",
      "\t* token\\_name\n",
      "\t* token\\_symbol\n",
      "\t* total\\_supply\n",
      "\t* decimals\n",
      "\t* smart\\_contract\\_address\n",
      "3. Wallet:\n",
      "\t* wallet\\_id (unique identifier)\n",
      "\t* user\\_id (foreign key, related to User)\n",
      "\t* public\\_key\n",
      "\t* private\\_key (encrypted)\n",
      "4. TokenBalance:\n",
      "\t* token\\_balance\\_id (unique identifier)\n",
      "\t* wallet\\_id (foreign key, related to Wallet)\n",
      "\t* token\\_id (foreign key, related to Token)\n",
      "\t* balance\n",
      "5. Transaction:\n",
      "\t* transaction\\_id (unique identifier)\n",
      "\t* sender\\_wallet\\_id (foreign key, related to Wallet)\n",
      "\t* receiver\\_wallet\\_id (foreign key, related to Wallet)\n",
      "\t* token\\_id (foreign key, related to Token)\n",
      "\t* amount\n",
      "\t* transaction\\_fee\n",
      "\t* timestamp\n",
      "\t* transaction\\_hash\n",
      "\t* status (pending, success, failed)\n",
      "6. Reward:\n",
      "\t* reward\\_id (unique identifier)\n",
      "\t* token\\_id (foreign key, related to Token)\n",
      "\t* reward\\_name\n",
      "\t* description\n",
      "\t* required\\_tokens\n",
      "\t* reward\\_image (optional)\n",
      "\t* start\\_date\n",
      "\t* end\\_date\n",
      "7. RewardRedemption:\n",
      "\t* redemption\\_id (unique identifier)\n",
      "\t* user\\_id (foreign key, related to User)\n",
      "\t* reward\\_id (foreign key, related to Reward)\n",
      "\t* redemption\\_date\n",
      "\t* status (pending, success, failed)\n",
      "8. Merchant:\n",
      "\t* merchant\\_id (unique identifier)\n",
      "\t* merchant\\_name\n",
      "\t* email\n",
      "\t* phone\\_number\n",
      "\t* address\n",
      "9. MerchantTokenAllocation:\n",
      "\t* allocation\\_id (unique identifier)\n",
      "\t* merchant\\_id (foreign key, related to Merchant)\n",
      "\t* token\\_id (foreign key, related to Token)\n",
      "\t* allocation\\_amount\n",
      "\t* start\\_date\n",
      "\t* end\\_date\n",
      "\n",
      "This data model captures the primary entities involved in a data-enriched token-based loyalty program, including users, tokens, wallets, transactions, rewards, redemptions, and merchants. You can further expand and modify the model to incorporate additional features or requirements specific to your use case.[-100 * 22]Here is a set of RESTful API endpoints to manage the data model mentioned above. These endpoints will allow you to perform CRUD (Create, Read, Update, Delete) operations on the entities.\n",
      "\n",
      "User:\n",
      "\n",
      "* POST /users: Create a new user.\n",
      "* GET /users: Retrieve a list of users.\n",
      "* GET /users/{user\\_id}: Retrieve a specific user by user\\_id.\n",
      "* PUT /users/{user\\_id}: Update a specific user's information.\n",
      "* DELETE /users/{user\\_id}: Delete a specific user.\n",
      "\n",
      "Token:\n",
      "\n",
      "* POST /tokens: Create a new token.\n",
      "* GET /tokens: Retrieve a list of tokens.\n",
      "* GET /tokens/{token\\_id}: Retrieve a specific token by token\\_id.\n",
      "* PUT /tokens/{token\\_id}: Update a specific token's information.\n",
      "* DELETE /tokens/{token\\_id}: Delete a specific token.\n",
      "\n",
      "Wallet:\n",
      "\n",
      "* POST /wallets: Create a new wallet.\n",
      "* GET /wallets: Retrieve a list of wallets.\n",
      "* GET /wallets/{wallet\\_id}: Retrieve a specific wallet by wallet\\_id.\n",
      "* PUT /wallets/{wallet\\_id}: Update a specific wallet's information.\n",
      "* DELETE /wallets/{wallet\\_id}: Delete a specific wallet.\n",
      "\n",
      "TokenBalance:\n",
      "\n",
      "* POST /token-balances: Create a new token balance.\n",
      "* GET /token-balances: Retrieve a list of token balances.\n",
      "* GET /token-balances/{token\\_balance\\_id}: Retrieve a specific token balance by token\\_balance\\_id.\n",
      "* PUT /token-balances/{token\\_balance\\_id}: Update a specific token balance's information.\n",
      "* DELETE /token-balances/{token\\_balance\\_id}: Delete a specific token balance.\n",
      "\n",
      "Transaction:\n",
      "\n",
      "* POST /transactions: Create a new transaction.\n",
      "* GET /transactions: Retrieve a list of transactions.\n",
      "* GET /transactions/{transaction\\_id}: Retrieve a specific transaction by transaction\\_id.\n",
      "* PUT /transactions/{transaction\\_id}: Update a specific transaction's information.\n",
      "\n",
      "Reward:\n",
      "\n",
      "* POST /rewards: Create a new reward.\n",
      "* GET /rewards: Retrieve a list of rewards.\n",
      "* GET /rewards/{reward\\_id}: Retrieve a specific reward by reward\\_id.\n",
      "* PUT /rewards/{reward\\_id}: Update a specific reward's information.\n",
      "* DELETE /rewards/{reward\\_id}: Delete a specific reward.\n",
      "\n",
      "RewardRedemption:\n",
      "\n",
      "* POST /reward-redemptions: Create a new reward redemption.\n",
      "* GET /reward-redemptions: Retrieve a list of reward redemptions.\n",
      "* GET /reward-redemptions/{redemption\\_id}: Retrieve a specific reward redemption by redemption\\_id.\n",
      "* PUT /reward-redemptions/{redemption\\_id}: Update a specific reward redemption's information.\n",
      "* DELETE /reward-redemptions/{redemption\\_id}: Delete a specific reward redemption.\n",
      "\n",
      "Merchant:\n",
      "\n",
      "* POST /merchants: Create a new merchant.\n",
      "* GET /merchants: Retrieve a list of merchants.\n",
      "* GET /merchants/{merchant\\_id}: Retrieve a specific merchant by merchant\\_id.\n",
      "* PUT /merchants/{merchant\\_id}: Update a specific merchant's information.\n",
      "* DELETE /merchants/{merchant\\_id}: Delete a specific merchant.\n",
      "\n",
      "MerchantTokenAllocation:\n",
      "\n",
      "* POST /merchant-token-allocations: Create a new merchant token allocation.\n",
      "* GET /merchant-token-allocations: Retrieve a list of merchant token allocations.\n",
      "* GET /merchant-token-allocations/{allocation\\_id}: Retrieve a specific merchant token allocation by allocation\\_id.\n",
      "* PUT /merchant-token-allocations/{allocation\\_id}: Update a specific merchant token allocation's information.\n",
      "* DELETE /merchant-token-allocations/{allocation\\_id}: Delete a specific merchant token allocation.\n",
      "\n",
      "These API endpoints should provide a solid foundation for managing the data model of a data-enriched token-based loyalty program. You can expand or modify these endpoints as needed to cater to specific requirements or additional features.<|im_end|>\n",
      "[INFO:swift] Dataset Token Length: 537.607143±576.473667, min=29.000000, max=2048.000000, size=1092\n",
      "[INFO:swift] Dataset Token Length: 768.833333±319.871024, min=421.000000, max=1428.000000, size=6\n",
      "[INFO:swift] training_args: Seq2SeqTrainingArguments(\n",
      "_n_gpu=2,\n",
      "acc_strategy=token,\n",
      "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None},\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "additional_saved_files=[],\n",
      "auto_find_batch_size=False,\n",
      "bf16=True,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=1,\n",
      "dataloader_persistent_workers=False,\n",
      "dataloader_pin_memory=True,\n",
      "dataloader_prefetch_factor=None,\n",
      "ddp_backend=None,\n",
      "ddp_broadcast_buffers=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "dispatch_batches=None,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=False,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_do_concat_batches=True,\n",
      "eval_steps=50,\n",
      "evaluation_strategy=steps,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "generation_config=GenerationConfig {\n",
      "  \"chat_format\": \"chatml\",\n",
      "  \"do_sample\": true,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"max_new_tokens\": 2048,\n",
      "  \"max_window_size\": 6144,\n",
      "  \"pad_token_id\": 151645,\n",
      "  \"temperature\": 0.3,\n",
      "  \"top_k\": 20,\n",
      "  \"top_p\": 0.7\n",
      "}\n",
      ",\n",
      "generation_max_length=None,\n",
      "generation_num_beams=None,\n",
      "gradient_accumulation_steps=16,\n",
      "gradient_checkpointing=True,\n",
      "gradient_checkpointing_kwargs=None,\n",
      "greater_is_better=False,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_always_push=False,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "include_num_input_tokens_seen=False,\n",
      "include_tokens_per_second=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=0.0001,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=0,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/home/ph/LLM2/swift/tests/llm/output/qwen-14b-chat/v1-20240506-103132/runs,\n",
      "logging_first_step=True,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=5,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_kwargs={},\n",
      "lr_scheduler_type=linear,\n",
      "max_grad_norm=0.5,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=loss,\n",
      "mp_parameters=,\n",
      "neftune_noise_alpha=None,\n",
      "no_cuda=False,\n",
      "num_train_epochs=1,\n",
      "optim=adamw_torch,\n",
      "optim_args=None,\n",
      "optim_target_modules=None,\n",
      "output_dir=/home/ph/LLM2/swift/tests/llm/output/qwen-14b-chat/v1-20240506-103132,\n",
      "overwrite_output_dir=False,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=1,\n",
      "per_device_train_batch_size=1,\n",
      "predict_with_generate=False,\n",
      "prediction_loss_only=False,\n",
      "push_hub_strategy=push_best,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=False,\n",
      "report_to=['tensorboard'],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/home/ph/LLM2/swift/tests/llm/output/qwen-14b-chat/v1-20240506-103132,\n",
      "save_on_each_node=True,\n",
      "save_only_model=False,\n",
      "save_safetensors=True,\n",
      "save_steps=50,\n",
      "save_strategy=steps,\n",
      "save_total_limit=2,\n",
      "seed=42,\n",
      "skip_memory_metrics=True,\n",
      "sortish_sampler=True,\n",
      "split_batches=None,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "train_sampler_random=True,\n",
      "use_cpu=False,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.4,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.1,\n",
      ")\n",
      "[WARNING:swift] Authentication has expired, please re-login if you need to access private models or datasets.\n",
      "[ERROR:swift] Authentication token does not exist, failed to access model unknown which may not exist or may be                 private. Please login first.\n",
      "[ERROR:swift] Authentication token does not exist, failed to access model unknown which may not exist or may be                 private. Please login first.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'use_seedable_sampler'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 21\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mswift\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DatasetName, ModelType, SftArguments, sft_main\n\u001b[1;32m      8\u001b[0m sft_args \u001b[38;5;241m=\u001b[39m SftArguments(\n\u001b[1;32m      9\u001b[0m     model_type\u001b[38;5;241m=\u001b[39mModelType\u001b[38;5;241m.\u001b[39mqwen_14b_chat,\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# model_id_or_path='/home/ph/LLM/Qwen1.5/Qwen1.5-14B-Chat-GPTQ-Int4',  model_cache_dir='/home/ph/LLM/Qwen1.5/Qwen1.5-14B-Chat-GPTQ-Int4',\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m     model_name\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m猴乐乐\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhoulele\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     20\u001b[0m     model_author\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m同元智算\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTongyuan intelligence calculation\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 21\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43msft_main\u001b[49m\u001b[43m(\u001b[49m\u001b[43msft_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m best_model_checkpoint \u001b[38;5;241m=\u001b[39m output[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_model_checkpoint\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_model_checkpoint: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_model_checkpoint\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/LLM2/swift/swift/utils/run_utils.py:31\u001b[0m, in \u001b[0;36mget_main.<locals>.x_main\u001b[0;34m(argv, **kwargs)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     30\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mremaining_argv: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mremaining_argv\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 31\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mllm_x\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEnd time of running main: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS.\u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     34\u001b[0m )\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/LLM2/swift/swift/llm/sft.py:238\u001b[0m, in \u001b[0;36mllm_sft\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mcheck_model_is_latest \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    236\u001b[0m     trainer_kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcheck_model\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 238\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mSeq2SeqTrainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_collator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_collator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtrainer_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    247\u001b[0m trainer\u001b[38;5;241m.\u001b[39msft_args \u001b[38;5;241m=\u001b[39m args\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_torchacc():\n",
      "File \u001b[0;32m~/LLM2/swift/swift/trainers/trainers.py:39\u001b[0m, in \u001b[0;36mSeq2SeqTrainer.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;66;03m# performance\u001b[39;00m\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mperf: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     42\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgen_time\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;241m0.\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mget_trainable_parameters\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     50\u001b[0m     }\n",
      "File \u001b[0;32m~/LLM2/swift/swift/trainers/mixin.py:285\u001b[0m, in \u001b[0;36mSwiftMixin.__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics, **kwargs)\u001b[0m\n\u001b[1;32m    283\u001b[0m     model\u001b[38;5;241m.\u001b[39m_hf_peft_config_loaded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;66;03m# mro\u001b[39;00m\n\u001b[0;32m--> 285\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_collator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_collator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreprocess_logits_for_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreprocess_logits_for_metrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_quantized \u001b[38;5;129;01mand\u001b[39;00m use_swift:\n\u001b[1;32m    299\u001b[0m     model\u001b[38;5;241m.\u001b[39m_hf_peft_config_loaded \u001b[38;5;241m=\u001b[39m _hf_peft_config_loaded\n",
      "File \u001b[0;32m~/anaconda3/envs/torch2.1/lib/python3.9/site-packages/transformers/trainer_seq2seq.py:57\u001b[0m, in \u001b[0;36mSeq2SeqTrainer.__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     45\u001b[0m     model: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPreTrainedModel\u001b[39m\u001b[38;5;124m\"\u001b[39m, nn\u001b[38;5;241m.\u001b[39mModule] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     55\u001b[0m     preprocess_logits_for_metrics: Optional[Callable[[torch\u001b[38;5;241m.\u001b[39mTensor, torch\u001b[38;5;241m.\u001b[39mTensor], torch\u001b[38;5;241m.\u001b[39mTensor]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     56\u001b[0m ):\n\u001b[0;32m---> 57\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_collator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_collator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompute_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreprocess_logits_for_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreprocess_logits_for_metrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;66;03m# Override self.model.generation_config if a GenerationConfig is specified in args.\u001b[39;00m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;66;03m# Priority: args.generation_config > model.generation_config > default GenerationConfig.\u001b[39;00m\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgeneration_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/torch2.1/lib/python3.9/site-packages/transformers/trainer.py:388\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeepspeed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_in_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 388\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_accelerator_and_postprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;66;03m# memory metrics - must set up as early as possible\u001b[39;00m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_memory_tracker \u001b[38;5;241m=\u001b[39m TrainerMemoryTracker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mskip_memory_metrics)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch2.1/lib/python3.9/site-packages/transformers/trainer.py:4364\u001b[0m, in \u001b[0;36mTrainer.create_accelerator_and_postprocess\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   4361\u001b[0m     args\u001b[38;5;241m.\u001b[39mupdate(accelerator_config)\n\u001b[1;32m   4363\u001b[0m \u001b[38;5;66;03m# create accelerator object\u001b[39;00m\n\u001b[0;32m-> 4364\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator \u001b[38;5;241m=\u001b[39m \u001b[43mAccelerator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4365\u001b[0m \u001b[38;5;66;03m# some Trainer classes need to use `gather` instead of `gather_for_metrics`, thus we store a flag\u001b[39;00m\n\u001b[1;32m   4366\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mgather_for_metrics\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'use_seedable_sampler'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '6'\n",
    "import sys\n",
    "sys.path.append('/home/ph/LLM2/swift')\n",
    "sys.path.insert(0,'/home/ph/LLM2/swift')\n",
    "from swift.llm import DatasetName, ModelType, SftArguments, sft_main\n",
    "\n",
    "sft_args = SftArguments(\n",
    "    model_type=ModelType.qwen_14b_chat,\n",
    "    # model_id_or_path='/home/ph/LLM/Qwen1.5/Qwen1.5-14B-Chat-GPTQ-Int4',  model_cache_dir='/home/ph/LLM/Qwen1.5/Qwen1.5-14B-Chat-GPTQ-Int4',\n",
    "    dataset=[DatasetName.sharegpt_gpt4_mini],\n",
    "    train_dataset_sample=1000,\n",
    "    logging_steps=5,\n",
    "    max_length=2048,\n",
    "    warmup_ratio=0.4,\n",
    "    output_dir='output',\n",
    "    lora_target_modules=['ALL'],   # 在所有的linear层(包括qkvo以及mlp)加lora. 这通常是效果最好的.\n",
    "    self_cognition_sample=500,\n",
    "    model_name=['猴乐乐', 'houlele'],\n",
    "    model_author=['同元智算', 'Tongyuan intelligence calculation'])\n",
    "output = sft_main(sft_args)\n",
    "best_model_checkpoint = output['best_model_checkpoint']\n",
    "print(f'best_model_checkpoint: {best_model_checkpoint}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2.1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
